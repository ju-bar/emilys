{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Script\n",
    "# Calibration of the diffraction projection\n",
    "# from a diffraction pattern of a known crystal\n",
    "#\n",
    "# by J. Barthel / Forschungszentrum Jülich GmbH, Jülich, Germany\n",
    "# email: ju.barthel@fz-juelich.de\n",
    "#\n",
    "# 2019 July 3\n",
    "#\n",
    "# Part of the emilys project: https://github.com/ju-bar/emilys\n",
    "# published under the GNU GPL 3.0 License\n",
    "#\n",
    "# - record a diffraction pattern with as parallel illumination as possible\n",
    "# - avoid recording noisy data (make long exposures)\n",
    "# - avoid over saturation of the detector\n",
    "# - avoid strong diffraction defocus or astigmatism\n",
    "#\n",
    "# Some of the procedure steps are commented extensively, indicating\n",
    "# steps with fudge parameters. Tuning these parameters may help to\n",
    "# improve the quality of the result. It is recommended to note changes\n",
    "# and keep the original values in comments.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, Arrow\n",
    "from scipy.optimize import curve_fit, minimize\n",
    "import emilys.image.arrayplot as aplt\n",
    "from emilys.numerics.mc import mc_image_pos_maximize\n",
    "from emilys.image.imagedata import image_pos_sum\n",
    "import emilys.numerics.cluster as clus\n",
    "from emilys.optics.projection import projection_func_2d as proj2d\n",
    "%matplotlib inline\n",
    "# development imports on autoreload\n",
    "#%load_ext autoreload\n",
    "#%autoreload 1\n",
    "#%aimport emilys.optics.projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sworkdir = '../data/' # ! Set working directory !\n",
    "ldat0 = np.fromfile(sworkdir + 'dif_cal_avg.dat', dtype='float64') # load the image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = np.array([256,256]) # ! Set image dimension !\n",
    "pcenter = np.array([132.,120.]) # ! Set center of peak search area !\n",
    "prange = 70. # ! Set range of peak search area !\n",
    "limg0 = ldat0.reshape(ndim) # get the image in shape\n",
    "%matplotlib inline\n",
    "fig0, ax0 = aplt.arrayplot2d(limg0**0.3,2,'inferno') # plot image and enhance low at low intensities\n",
    "prangecircle = Circle(pcenter, prange, color='w', fill=False)\n",
    "ax0.add_patch(prangecircle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locating local minima using a Monte-Carlo approach\n",
    "# This cell does some initializations. The Monte-Carlo is done with the cell below.\n",
    "# - determine the intensity variations for pixels close to the range circle defined above\n",
    "sr1 = 0.\n",
    "sr2 = 0.\n",
    "srn = 0\n",
    "si = 0.\n",
    "for j in range(0,ndim[0]):\n",
    "    for i in range(0,ndim[1]):\n",
    "        if np.abs(np.sqrt((i-pcenter[0])**2 + (j-pcenter[1])**2) - prange) < 1.:\n",
    "            si = limg0[j,i]\n",
    "            sr1 += si\n",
    "            sr2 += si**2\n",
    "            srn += 1\n",
    "rmean = sr1 / srn\n",
    "rsdev = np.sqrt(sr2 / srn - rmean*rmean)\n",
    "print('- intensity on range limit (mean, sdev):',[rmean,rsdev])\n",
    "# - initialize a list of points (one for each second second pixel in the range)\n",
    "lrpt = np.array([])\n",
    "nrpt = 0\n",
    "for j in range(0,ndim[0],2):\n",
    "    for i in range(0,ndim[1],2):\n",
    "        if np.sqrt((i - pcenter[0])**2 + (j - pcenter[1])**2) < prange:\n",
    "            if nrpt == 0:\n",
    "                lrpt = np.array([[1.*i,1.*j]])\n",
    "            else:\n",
    "                lrpt = np.concatenate((lrpt,np.array([[1.*i,1.*j]])))\n",
    "            nrpt += 1\n",
    "print('- test points for peak finding:', lrpt.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will let the test points in lrpt 'walk' towards local maxima\n",
    "# - repeat until iterations < itmax or improvement is small (<1%)\n",
    "# - decrease 'pstep' and 'tempr' to improve / converge\n",
    "itmax = 100 # number of iterations (100 is OK)\n",
    "tempr = rsdev/100 # temperture (lower or about the rms noise estimate)\n",
    "pstep = 1. # rms walking step size (1 pixel is OK)\n",
    "s0 = image_pos_sum(limg0, lrpt)\n",
    "nit = mc_image_pos_maximize(limg0, lrpt, pstep, tempr, itmax)\n",
    "s1 = image_pos_sum(limg0, lrpt)\n",
    "print('- initial: {:8.3e}, final: {:8.3e}, change: {:6.2f}% , iter: {:d}'.format(s0,s1,100.*(s1/s0 - 1.),nit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the image and overlay the test points.\n",
    "# This may help to decide when to stop iterating the cell above.\n",
    "fig1, ax1 = aplt.arrayplot2d(limg0**0.3,2,'inferno') # plot image\n",
    "# add test points\n",
    "ax1.scatter(*lrpt.T,s=1.,c='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a primitive cluster recognition on the point distribution lrpt\n",
    "clrad0 = 4. # ! Set cluster radius threshold in pixels ! (choose to separate peaks)\n",
    "ierr = 0\n",
    "lcl = clus.cluster_l2(lrpt, clrad0)\n",
    "print('- number of clusters:', len(lcl.lcluster)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove small clusters\n",
    "# - Define the cluster population threshold!\n",
    "#   We expect a uniform distribution of maxima in the search range.\n",
    "#   Given the number of points N and the number of clusters M, a good\n",
    "#   cluster should be populated by about N/M points. Clusters with\n",
    "#   populations 'well below' this expectation may be false positives.\n",
    "#   The relative threshold 'rpopthr' in the range 0 ... 1 expresses\n",
    "#   what we mean by 'well below'. Take care not to exclude too many\n",
    "#   good clusters by checking the outcome with the plot in the cell below.\n",
    "rpopthr = 0.2 # ! Set this to identify low population thresholds ! (0 ... 1, 0.1 is OK)\n",
    "nclpop = int(lrpt.shape[0] / len(lcl.lcluster) * rpopthr)\n",
    "print('- reducing to clusters with more than ', nclpop,' votes ...')\n",
    "lpk0 = []\n",
    "for l in range(0, len(lcl.lcluster)):\n",
    "    if len(lcl.lcluster[l].population) > nclpop:\n",
    "        lpk0.append(lcl.lcluster[l].mean)\n",
    "print('-',len(lpk0),' peaks suggested.')\n",
    "fig2, ax2 = aplt.arrayplot2d(limg0**0.3, 2, 'inferno') # plot image\n",
    "# show points\n",
    "lpk0t = np.transpose(lpk0)\n",
    "ax2.scatter(*lpk0t,s=2.,c='cyan')\n",
    "# calculate smallest distance found ...\n",
    "dmin = ndim[0] + ndim[1]\n",
    "for l in range(0, len(lpk0)-1):\n",
    "    pl = np.array(lpk0[l])\n",
    "    for k in range(l+1, len(lpk0)):\n",
    "        pk = np.array(lpk0[k])\n",
    "        vd = pk - pl\n",
    "        dmin = min(dmin, np.sqrt(np.dot(vd,vd)))\n",
    "pkdmin0 = dmin\n",
    "print('- smallest distance [pix]:', pkdmin0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cluster mean values, as expected positions of local maxima,\n",
    "# are refined further by fitting a Gaussian peak function to the\n",
    "# each of the local areas.\n",
    "# - initialize a list of peak data\n",
    "# 'pkrad' is the expected radius of the peak area, taken from the\n",
    "# smallest peak distance 'pkdmin0', measured above.\n",
    "pkrad = 0.5*(pkdmin0-1.) # ! Set pixel radius to include data (keep it small) !\n",
    "npk = len(lpk0) # get number of peaks\n",
    "lpk0dat = [] # initialize list of data for fitting\n",
    "# - collect data\n",
    "for l in range(0,npk): # loop through pre-estimated peak positions\n",
    "    lpkdat = [] # initialize list of data\n",
    "    i0, j0 = np.floor(lpk0[l] - pkrad).astype(int)\n",
    "    i1, j1 = np.ceil(lpk0[l] + pkrad).astype(int)\n",
    "    for j in range(j0, j1+1):\n",
    "        for i in range(i0, i1+1):\n",
    "            lpkdat.append([i,j,limg0[j,i]])\n",
    "    lpk0dat.append(lpkdat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function 'pkfun' for peak fitting\n",
    "#\n",
    "# Remarks:\n",
    "# 1) Since we are not really able to describe the functionality of the\n",
    "#    intensity maxima, the actual function dynamics are not very important.\n",
    "# 2) It is recommended to use a rotationally symmetric function. This will give\n",
    "#    positions roughly equivalent to the center of mass.\n",
    "# 3) An implementation evaluating the center of mass in the local area would\n",
    "#    be also reasonable and perhaps even more stable numerically. However, in\n",
    "#    case of locating minima, the data would need a sign reversal.\n",
    "# 4) It could be worth investigating to include a bi-linear background\n",
    "#    component in the function if the data suggests that and peaks amplitudes\n",
    "#    are weak against the background slope. This will however require that the\n",
    "#    peaks widths are smaller than the size of the areas. Such a background\n",
    "#    slope correction would also be required for a center of mass approach.\n",
    "# \n",
    "def pkfun(x_tuple, xc0, xc1, w, a0, a1):\n",
    "    # 2D Gaussian peak function: (xdata,*a) -> y\n",
    "    # - symmetric, no background slope components\n",
    "    # - xdata = [[x00,x01,...,x0N],[x10,x11,...,x1N]]\n",
    "    # - parameters: \n",
    "    #     xc0, xc1 : center  position\n",
    "    #     w : half-width (rms)\n",
    "    #     a0 : constant background\n",
    "    #     a1 : amplitdue\n",
    "    (x0, x1) = x_tuple\n",
    "    dx0 = x0 - xc0\n",
    "    dx1 = x1 - xc1\n",
    "    d2 = dx0*dx0 + dx1*dx1\n",
    "    w2 = w**2\n",
    "    vexp = 0. # init for abnormal width\n",
    "    if (w2 > 0.): # normal width\n",
    "        vexp = np.exp( -0.5 * d2 / w2 )\n",
    "    return a0 + a1 * vexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit peaks to the local area data\n",
    "# Reject solutions with:\n",
    "# - shifts larger than half the local area radius\n",
    "# - widths larger than the local area radius\n",
    "# - amplitudes smaller than 2 x the noise level 'rsdev' estimated above\n",
    "#\n",
    "lpk1 = [] # init resulting peak parameter list\n",
    "for ipk in range(0,npk): # loop over all estimated peak positions\n",
    "    # prepate fit data\n",
    "    pkx = lpk0[ipk]\n",
    "    pkdat = np.array(lpk0dat[ipk])\n",
    "    x = pkdat.T[0] # x data positions\n",
    "    y = pkdat.T[1] # y data positions\n",
    "    z = pkdat.T[2] # intensity values\n",
    "    prm0 = [pkx[0], pkx[1], 0.5*pkrad, np.min(z), np.max(z) - np.min(z)] # initial parameter set\n",
    "    solprm, solcov = curve_fit(pkfun, np.vstack((x,y)), z, prm0) # call scipy.optimize.curve_fit\n",
    "    solerr = np.sqrt(np.diag(solcov)) # get parameter error estimates (ignoring covariances)\n",
    "    vcshift = pkx - np.array([solprm[0],solprm[1]]) # measure shift to previous position estimate\n",
    "    if np.sqrt(np.dot(vcshift,vcshift)) < 0.5 * pkrad and solprm[2] < pkrad and 2 * rsdev < solprm[4]:\n",
    "        lpk1.append([solprm,solerr]) # accept the fit\n",
    "npkf = len(lpk1) # number of accepted peaks \n",
    "lpkf = np.array(lpk1) # fit parameters as numpy.array\n",
    "print('-', npkf, ' peaks accepted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the image with circles indicating measured peak positions and widths\n",
    "fig3, ax3 = aplt.arrayplot2d(limg0**0.3,2,'inferno') # plot image\n",
    "# show points\n",
    "lpost = np.transpose(lpkf)[0:3,0]\n",
    "ax3.scatter(*lpost[0:2],s=16*lpost[2]**2, facecolors='none', edgecolors='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the peaks with a lattice (projected reciprocal lattice of the crystal)\n",
    "# - Locate the peak closest to the image center.\n",
    "#posc = 0.5 * ndim # ! Set the center position for the peak pattern !\n",
    "posc = 0.5 * ndim - [0.,10.] # ! Set the center position for the peak pattern !\n",
    "dmin = np.sqrt(np.dot(lpkf[0,0,0:2] - posc,lpkf[0,0,0:2] - posc))\n",
    "imin = 0\n",
    "for l in range(1, npkf):\n",
    "    vd = lpkf[l,0,0:2] - posc\n",
    "    dist = np.sqrt(np.dot(vd,vd))\n",
    "    if dist < dmin:\n",
    "        imin = l\n",
    "        dmin = dist\n",
    "icenter = imin\n",
    "pcenter = lpkf[icenter,0,0:2]\n",
    "print('- choosing center peak (ID, pos):', [icenter, [pcenter[0],pcenter[1]]])\n",
    "# - Locate the next peak pointing along the horizontal axis ...\n",
    "dmin = 1. * ndim[0]\n",
    "imin = -1\n",
    "for l in range(0, npkf):\n",
    "    vd = lpkf[l,0,0:2] - pcenter\n",
    "    dist = np.sqrt(np.dot(vd,vd))\n",
    "    dpx = np.dot(vd,np.array([1.,0]))\n",
    "    if dist < dmin and l != icenter and dpx > pkrad:\n",
    "        imin = l\n",
    "        dmin = dist\n",
    "iplane0 = imin\n",
    "pplane0 = lpkf[iplane0,0,0:2]\n",
    "vplane0 = pplane0 - pcenter\n",
    "print('- x-axis (ID, pos):', [iplane0, dmin, [vplane0[0],vplane0[1]]])\n",
    "#    ... and one in the perpendicular direction\n",
    "vpy = np.dot(np.array([[0.,-1],[1.,0.]]),vplane0 / np.sqrt(np.dot(vplane0,vplane0)))\n",
    "dmin = 1. * ndim[0]\n",
    "imin = -1\n",
    "for l in range(0, npkf):\n",
    "    vd = lpkf[l,0,0:2] - pcenter\n",
    "    dist = np.sqrt(np.dot(vd,vd))\n",
    "    dpy = np.dot(vd,vpy)\n",
    "    if dist < dmin and l != icenter and dpy > 0.9*dist:\n",
    "        imin = l\n",
    "        dmin = dist\n",
    "iplane1 = imin\n",
    "pplane1 = lpkf[iplane1,0,0:2]\n",
    "vplane1 = pplane1 - pcenter\n",
    "print('- y-axis (ID, pos):', [iplane1, dmin, [vplane1[0],vplane1[1]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the chosen basis by arrows in a plot\n",
    "fig4, ax4 = aplt.arrayplot2d(limg0**0.2,2,'inferno') # plot image\n",
    "# show points\n",
    "lpost = np.transpose(lpkf)[0:3,0]\n",
    "ax4.scatter(*lpost[0:2],s=16*lpost[2]**2, facecolors='none', edgecolors='w')\n",
    "parr0 = Arrow(pcenter[0], pcenter[1], vplane0[0], vplane0[1], color='#2020ff')\n",
    "ax4.add_patch(parr0)\n",
    "parr1 = Arrow(pcenter[0], pcenter[1], vplane1[0], vplane1[1], color='#ff2020')\n",
    "ax4.add_patch(parr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the plot and assign [hk] indices to the two arrows !\n",
    "# This requires, that the two arrows are not parallel or anti-parallel.\n",
    "hk0 = [1,0] # ! Set the [hk] for the BLUE ARROW pointing right !\n",
    "hk1 = [0,2] # ! Set the [hk] for the RED ARROW pointing up !\n",
    "# Set parameters determining the k-space scale, i.e. the projected Bragg spot vectors.\n",
    "q10 = [2.563, 0.] # ! Set the reciprocal space vector corresponding to [10] in physical units !\n",
    "q01 = [0., 2.563] # ! Set the reciprocal space vector corresponding to [01] in physical units !\n",
    "# Set the center of the projection.\n",
    "# This is a reference point, required for non-linear distortions.\n",
    "p00 = [127.64, 125.63] # ! Set the position of the zero beam / probe-forming aperture center !\n",
    "#\n",
    "# translate the given pixel basis vectors to grid basis vectors\n",
    "mhk = np.array([hk0,hk1])\n",
    "mhki = np.linalg.inv(mhk)\n",
    "pbase = np.array([vplane0,vplane1])\n",
    "bhk = np.dot(mhki,pbase).T\n",
    "bhki = np.linalg.inv(bhk)\n",
    "#\n",
    "# Predict peak positions from the parameters and keep those close to the measured peaks\n",
    "lpkfhk = np.zeros((npkf,2), dtype=int)\n",
    "lpkfpred = np.zeros((npkf,2), dtype=float)\n",
    "for l in range(0, npkf): # loop over all peaks\n",
    "    vpos = lpkf[l,0,0:2] - pcenter\n",
    "    lpkfhk[l] = np.round(np.dot(bhki,vpos)).astype(int)\n",
    "    lpkfpred[l] = np.dot(bhk,lpkfhk[l]) + pcenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot measured (white) vs. predicted (blue) peak positions.\n",
    "# The prediction should reflect the measured pattern.\n",
    "# In case of strong deviations, you may\n",
    "# - choose a different center 'posc' above, thereby selecting\n",
    "#   other initial basis vectors\n",
    "# - reject small peaks in the center part by playing with\n",
    "#   any of the rejection mechanisms applyied after cluster\n",
    "#   recognition and peak fitting (population, width, etc.)\n",
    "# - decrease the initial search range 'prange' and restart.\n",
    "#\n",
    "# !!! Warning !!!\n",
    "#   It is very important here, that each prediction coincides\n",
    "#   with one of the peaks. It must not fit perfectly, but there\n",
    "#   should be no misses / gaps in the predicted pattern which\n",
    "#   are not present in the peak pattern.\n",
    "#     \n",
    "fig5, ax5 = aplt.arrayplot2d(limg0**0.3,2,'inferno') # plot image\n",
    "# show points\n",
    "parr0 = Arrow(pcenter[0], pcenter[1], vplane0[0], vplane0[1], color='#2020ff')\n",
    "ax5.add_patch(parr0)\n",
    "parr1 = Arrow(pcenter[0], pcenter[1], vplane1[0], vplane1[1], color='#ff2020')\n",
    "ax5.add_patch(parr1)\n",
    "lpost = np.transpose(lpkf)[0:3,0]\n",
    "ax5.scatter(*lpost[0:2],s=16*lpost[2]**2, facecolors='none', edgecolors='w')\n",
    "ax5.scatter(*lpkfpred.T,s=16*lpost[2]**2, facecolors='#4060ffa0', edgecolors='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit projection functions: k -> pixel to the set of peak positions\n",
    "# using the lattice assignment made above.\n",
    "# The fitting is done for pixel coordinates as functions of k in\n",
    "# complex number notation.\n",
    "#\n",
    "# We want the outcome of the projection such that p(k'=0) = p00\n",
    "# and therefore consider that the current k = 0 needs an offset k0,\n",
    "# such that k' = k + k0. k0 will be fitted.\n",
    "#\n",
    "# - collect the k data and pixel data in complex number notation\n",
    "kdata = np.zeros((npkf,2), dtype=float)\n",
    "pdata = np.zeros((npkf,2), dtype=float)\n",
    "m_k = np.array([q10,q01]) # physical lattice basis\n",
    "m_ki = np.linalg.inv(m_k)\n",
    "kdata = np.dot(m_k, lpkfhk.T).T # physical lattice vectors k\n",
    "pdata = lpkf[:,0,0:2] - p00 # pixel lattice points, recentered to k=0\n",
    "sdata = lpkf[:,1,0:2] # position errors\n",
    "dp0 = pcenter - p00 # pixel shift between p(k=0) and test pattern\n",
    "# - Set the maximum order of distorting aberrations (min. 1!)\n",
    "ndist = 1\n",
    "prj = proj2d(ndist) # init a 2d projection object\n",
    "#prj = emilys.optics.projection.projection_func_2d(ndist)\n",
    "m_kp1 = np.dot(bhk,m_ki) # this is an initial transformation from k -> pixel\n",
    "v_k0 = np.dot(np.linalg.inv(m_kp1),dp0) # approximated shift of the k-pattern to k = 0\n",
    "prjc0 = np.zeros(2*prj.num_terms, dtype=float) # init number of parameters\n",
    "prjc0[2:6] = m_kp1.T.flatten()\n",
    "luse = np.full(prj.num_terms, 1, dtype=int) # use flags\n",
    "luse[0] = 0\n",
    "#luse[6:10] = 0\n",
    "# fit the projection parameters to match model to measurement\n",
    "prjk0cf, prjccov, sqrdev = prj.fit_x0_lcoeff(kdata, pdata, ysigm=sdata, x0=v_k0, lcoeff0=prjc0, luse=luse)\n",
    "prjcf = np.zeros(2*prj.num_terms, dtype=float)\n",
    "prjcf[2:] = prjk0cf[2:] # pure projection result\n",
    "v_k0f = prjk0cf[0:2] # k shift\n",
    "lpkmpred = prj.project(kdata+v_k0f, prjcf, luse) + p00 # model predicted peak positions\n",
    "# print a list of results\n",
    "print('Fit results:')\n",
    "print('- k0 : [{:8.5f},{:8.5f}] +/- [{:8.5f},{:8.5f}]'.format(*v_k0f,np.sqrt(prjccov[0,0]),np.sqrt(prjccov[1,1])))\n",
    "for i in range(1, prj.num_terms):\n",
    "    if luse[i] == 0: continue\n",
    "    j = 2*i\n",
    "    l, k = prj.get_lk(i)\n",
    "    print('- a{:d}{:d}: [{:8.5f},{:8.5f}] +/- [{:8.5f},{:8.5f}]'.format(l,k,prjcf[j],prjcf[1+j],np.sqrt(prjccov[j,j]),np.sqrt(prjccov[1+j,1+j])))\n",
    "print('- rms resid. [pix]: {:8.4f}'.format(np.sqrt(np.mean(sdata**2)*sqrdev/(2*(npkf-np.sum(luse)-1)))))\n",
    "# plot fit\n",
    "fig6, ax6 = aplt.arrayplot2d(limg0**0.3,2,'inferno') # plot image\n",
    "# show points\n",
    "lpost = np.transpose(lpkf)[0:3,0]\n",
    "ax6.scatter(*lpost[0:2],s=16*lpost[2]**2, facecolors='none', edgecolors='w') # measured\n",
    "ax6.scatter(*lpkmpred.T,s=16*lpost[2]**2, facecolors='#40ff2070', edgecolors='none') # model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection function:\n",
    "#\n",
    "# Take care when interpreting the projection function.\n",
    "# The meaning of each coefficient is specific to how the function is defined:\n",
    "#\n",
    "#    [p0,p1] = proj2d.project([q0,q1])\n",
    "#            = sum_l,k [alk0,alk1] * binomial(l+k,l) * q0**l * q1**k\n",
    "#\n",
    "# where binomial(l+k,l) is a binomial factor\n",
    "#\n",
    "#    binomial(l+k,l) = (l+k)! / l! / k!\n",
    "#\n",
    "# You can may use proj2d.backproject([p0,p1]) for the inverse calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload # load extension for the auto-reload magic\n",
    "# %autoreload 1 # set the autoreload for module functions only for those imported with the %aimport magic\n",
    "# %autoreload 2 # set the autoreload for all module functions, except for those excluded by the %aimport magic\n",
    "# %aimport <module>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}